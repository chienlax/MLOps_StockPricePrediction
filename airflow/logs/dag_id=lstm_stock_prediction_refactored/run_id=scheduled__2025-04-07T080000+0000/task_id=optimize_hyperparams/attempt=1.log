[2025-04-14T08:00:05.332+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-14T08:00:05.347+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: lstm_stock_prediction_refactored.optimize_hyperparams scheduled__2025-04-07T08:00:00+00:00 [queued]>
[2025-04-14T08:00:05.353+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: lstm_stock_prediction_refactored.optimize_hyperparams scheduled__2025-04-07T08:00:00+00:00 [queued]>
[2025-04-14T08:00:05.354+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-14T08:00:05.362+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): optimize_hyperparams> on 2025-04-07 08:00:00+00:00
[2025-04-14T08:00:05.367+0000] {standard_task_runner.py:72} INFO - Started process 63185 to run task
[2025-04-14T08:00:05.370+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'lstm_stock_prediction_refactored', 'optimize_hyperparams', 'scheduled__2025-04-07T08:00:00+00:00', '--job-id', '89', '--raw', '--subdir', 'DAGS_FOLDER/lstm_refactored_dag.py', '--cfg-path', '/tmp/tmpyy549h4n']
[2025-04-14T08:00:05.371+0000] {standard_task_runner.py:105} INFO - Job 89: Subtask optimize_hyperparams
[2025-04-14T08:00:05.402+0000] {task_command.py:467} INFO - Running <TaskInstance: lstm_stock_prediction_refactored.optimize_hyperparams scheduled__2025-04-07T08:00:00+00:00 [running]> on host 38686bf18545
[2025-04-14T08:00:05.459+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***_team' AIRFLOW_CTX_DAG_ID='lstm_stock_prediction_refactored' AIRFLOW_CTX_TASK_ID='optimize_hyperparams' AIRFLOW_CTX_EXECUTION_DATE='2025-04-07T08:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-07T08:00:00+00:00'
[2025-04-14T08:00:05.461+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-14T08:00:05.471+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-14T08:00:05.472+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/src/models/optimize_hyperparams.py --config /opt/***/config/params.yaml']
[2025-04-14T08:00:05.481+0000] {subprocess.py:99} INFO - Output:
[2025-04-14T08:00:07.829+0000] {subprocess.py:106} INFO - mkdir -p failed for path /home/***/.cache/matplotlib: [Errno 13] Permission denied: '/home/***/.cache/matplotlib'
[2025-04-14T08:00:07.830+0000] {subprocess.py:106} INFO - Matplotlib created a temporary cache directory at /tmp/matplotlib-w7r72h65 because there was an issue with the default path (/home/***/.cache/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
[2025-04-14T08:00:10.224+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:00:10,224] A new study created in memory with name: no-name-699913dc-0cdb-4c93-81be-9126eb253e4a
[2025-04-14T08:00:14.288+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:00:14,288] Trial 0 finished with value: 0.06414762791246176 and parameters: {'batch_size': 96, 'hidden_size': 160, 'num_layers': 1, 'dropout_rate': 0.5, 'learning_rate': 0.0027387394169807572, 'model_type': 'lstm'}. Best is trial 0 with value: 0.06414762791246176.
[2025-04-14T08:00:17.970+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:00:17,970] Trial 1 finished with value: 0.09664101433008909 and parameters: {'batch_size': 16, 'hidden_size': 160, 'num_layers': 3, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.00458109839863442, 'model_type': 'lstm'}. Best is trial 0 with value: 0.06414762791246176.
[2025-04-14T08:00:27.009+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:00:27,009] Trial 2 finished with value: 0.0936899483203888 and parameters: {'batch_size': 112, 'hidden_size': 96, 'num_layers': 3, 'dropout_rate': 0.1, 'learning_rate': 0.0042456007776496794, 'model_type': 'lstm_cross_attention'}. Best is trial 0 with value: 0.06414762791246176.
[2025-04-14T08:00:28.192+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:00:28,192] Trial 3 finished with value: 0.10907857492566109 and parameters: {'batch_size': 112, 'hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.1, 'learning_rate': 0.00048501867571573715, 'model_type': 'lstm'}. Best is trial 0 with value: 0.06414762791246176.
[2025-04-14T08:00:36.025+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:00:36,024] Trial 4 finished with value: 0.0758888442069292 and parameters: {'batch_size': 128, 'hidden_size': 160, 'num_layers': 3, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.00012872049000483944, 'model_type': 'lstm_attention'}. Best is trial 0 with value: 0.06414762791246176.
[2025-04-14T08:01:22.245+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:01:22,244] Trial 5 finished with value: 0.04388521146029234 and parameters: {'batch_size': 48, 'hidden_size': 160, 'num_layers': 3, 'dropout_rate': 0.4, 'learning_rate': 0.00011148187213532144, 'model_type': 'lstm_cross_attention'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:02:31.439+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:02:31,439] Trial 6 finished with value: 0.05776153225451708 and parameters: {'batch_size': 96, 'hidden_size': 192, 'num_layers': 3, 'dropout_rate': 0.4, 'learning_rate': 0.0006656570802087648, 'model_type': 'lstm_cross_attention'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:02:35.623+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:02:35,623] Trial 7 finished with value: 0.05136304534971714 and parameters: {'batch_size': 128, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.002797383833800733, 'model_type': 'lstm'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:02:52.026+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:02:52,026] Trial 8 finished with value: 0.05479269288480282 and parameters: {'batch_size': 128, 'hidden_size': 160, 'num_layers': 2, 'dropout_rate': 0.2, 'learning_rate': 0.0033158875432962786, 'model_type': 'lstm_cross_attention'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:02:59.595+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:02:59,595] Trial 9 finished with value: 0.051086132414638996 and parameters: {'batch_size': 112, 'hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.005518068956182325, 'model_type': 'lstm_cross_attention'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:03:08.853+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:03:08,853] Trial 10 finished with value: 0.07192470598965883 and parameters: {'batch_size': 48, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.5, 'learning_rate': 0.00010890572033318331, 'model_type': 'lstm_attention'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:03:17.079+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:03:17,078] Trial 11 finished with value: 0.054210057482123375 and parameters: {'batch_size': 64, 'hidden_size': 96, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.008351602400608641, 'model_type': 'lstm_cross_attention'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:03:32.770+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:03:32,769] Trial 12 finished with value: 0.06260180845856667 and parameters: {'batch_size': 32, 'hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.4, 'learning_rate': 0.0002919401806236431, 'model_type': 'lstm_cross_attention'}. Best is trial 5 with value: 0.04388521146029234.
[2025-04-14T08:03:38.564+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:03:38,564] Trial 13 finished with value: 0.042969489470124245 and parameters: {'batch_size': 64, 'hidden_size': 96, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.001206845567526193, 'model_type': 'lstm_cross_attention'}. Best is trial 13 with value: 0.042969489470124245.
[2025-04-14T08:03:51.165+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:03:51,165] Trial 14 finished with value: 0.04835401910046736 and parameters: {'batch_size': 64, 'hidden_size': 96, 'num_layers': 2, 'dropout_rate': 0.4, 'learning_rate': 0.0015043838417244514, 'model_type': 'lstm_cross_attention'}. Best is trial 13 with value: 0.042969489470124245.
[2025-04-14T08:03:56.301+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:03:56,301] Trial 15 finished with value: 0.056445824448019266 and parameters: {'batch_size': 48, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.4, 'learning_rate': 0.0012099972424803093, 'model_type': 'lstm_cross_attention'}. Best is trial 13 with value: 0.042969489470124245.
[2025-04-14T08:04:02.700+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:04:02,700] Trial 16 finished with value: 0.06523629277944565 and parameters: {'batch_size': 80, 'hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.2, 'learning_rate': 0.0002753441442580506, 'model_type': 'lstm_attention'}. Best is trial 13 with value: 0.042969489470124245.
[2025-04-14T08:04:38.992+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:04:38,991] Trial 17 finished with value: 0.039006313867866994 and parameters: {'batch_size': 32, 'hidden_size': 192, 'num_layers': 2, 'dropout_rate': 0.1, 'learning_rate': 0.0016984136745207795, 'model_type': 'lstm_cross_attention'}. Best is trial 17 with value: 0.039006313867866994.
[2025-04-14T08:04:59.568+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:04:59,568] Trial 18 finished with value: 0.015712139056995512 and parameters: {'batch_size': 16, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.0017644961835672438, 'model_type': 'lstm_cross_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:05:05.970+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:05:05,970] Trial 19 finished with value: 0.08060888089239597 and parameters: {'batch_size': 16, 'hidden_size': 224, 'num_layers': 2, 'dropout_rate': 0.1, 'learning_rate': 0.0018457950228554219, 'model_type': 'lstm_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:05:19.842+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:05:19,841] Trial 20 finished with value: 0.0372494988143444 and parameters: {'batch_size': 32, 'hidden_size': 256, 'num_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.0007118037869953061, 'model_type': 'lstm_cross_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:06:25.511+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:06:25,510] Trial 21 finished with value: 0.01876808311790228 and parameters: {'batch_size': 32, 'hidden_size': 256, 'num_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.0007053738468631396, 'model_type': 'lstm_cross_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:07:11.864+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:07:11,864] Trial 22 finished with value: 0.020917925238609313 and parameters: {'batch_size': 32, 'hidden_size': 256, 'num_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.0008131153267463374, 'model_type': 'lstm_cross_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:07:27.239+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:07:27,239] Trial 23 finished with value: 0.03112382357940078 and parameters: {'batch_size': 16, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.0007641094529448803, 'model_type': 'lstm_cross_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:07:43.837+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:07:43,837] Trial 24 finished with value: 0.03906807340681553 and parameters: {'batch_size': 32, 'hidden_size': 256, 'num_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.00040005089504428835, 'model_type': 'lstm_cross_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:08:13.320+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:08:13,319] Trial 25 finished with value: 0.018410326912999153 and parameters: {'batch_size': 16, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.0009042945538407225, 'model_type': 'lstm_cross_attention'}. Best is trial 18 with value: 0.015712139056995512.
[2025-04-14T08:11:22.589+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:11:22,588] Trial 26 finished with value: 0.015698353108018637 and parameters: {'batch_size': 16, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.0019076221947736671, 'model_type': 'lstm_cross_attention'}. Best is trial 26 with value: 0.015698353108018637.
[2025-04-14T08:11:32.144+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:11:32,144] Trial 27 finished with value: 0.04746703999117017 and parameters: {'batch_size': 16, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.0024029838446248506, 'model_type': 'lstm_attention'}. Best is trial 26 with value: 0.015698353108018637.
[2025-04-14T08:11:39.772+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:11:39,772] Trial 28 finished with value: 0.03916098168119788 and parameters: {'batch_size': 16, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.0010573954890699057, 'model_type': 'lstm'}. Best is trial 26 with value: 0.015698353108018637.
[2025-04-14T08:12:11.372+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:12:11,371] Trial 29 finished with value: 0.01521440886426717 and parameters: {'batch_size': 48, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.002312157700886126, 'model_type': 'lstm_cross_attention'}. Best is trial 29 with value: 0.01521440886426717.
[2025-04-14T08:12:12.869+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:12:12,868] Trial 30 finished with value: 0.05988113023340702 and parameters: {'batch_size': 48, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0019651915141959643, 'model_type': 'lstm'}. Best is trial 29 with value: 0.01521440886426717.
[2025-04-14T08:12:46.497+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:12:46,497] Trial 31 finished with value: 0.01447057886980474 and parameters: {'batch_size': 16, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.002326615726800013, 'model_type': 'lstm_cross_attention'}. Best is trial 31 with value: 0.01447057886980474.
[2025-04-14T08:13:06.856+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:13:06,856] Trial 32 finished with value: 0.022047527646645904 and parameters: {'batch_size': 16, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0030315866613406153, 'model_type': 'lstm_cross_attention'}. Best is trial 31 with value: 0.01447057886980474.
[2025-04-14T08:13:32.349+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:13:32,349] Trial 33 finished with value: 0.019636006467044352 and parameters: {'batch_size': 16, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.004565520941535056, 'model_type': 'lstm_cross_attention'}. Best is trial 31 with value: 0.01447057886980474.
[2025-04-14T08:17:46.528+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:17:46,528] Trial 34 finished with value: 0.02516689896583557 and parameters: {'batch_size': 80, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.007051072665673798, 'model_type': 'lstm_cross_attention'}. Best is trial 31 with value: 0.01447057886980474.
[2025-04-14T08:18:00.625+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:18:00,625] Trial 35 finished with value: 0.08411973379552365 and parameters: {'batch_size': 32, 'hidden_size': 160, 'num_layers': 2, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0023037549012615705, 'model_type': 'lstm'}. Best is trial 31 with value: 0.01447057886980474.
[2025-04-14T08:18:48.564+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:18:48,562] Trial 36 finished with value: 0.04027448548004031 and parameters: {'batch_size': 48, 'hidden_size': 224, 'num_layers': 1, 'dropout_rate': 0.5, 'learning_rate': 0.0014698137850336632, 'model_type': 'lstm_cross_attention'}. Best is trial 31 with value: 0.01447057886980474.
[2025-04-14T08:19:18.582+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:19:18,582] Trial 37 finished with value: 0.014010190684348344 and parameters: {'batch_size': 16, 'hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0034994428915323724, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:19:31.914+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:19:31,914] Trial 38 finished with value: 0.02442048154771328 and parameters: {'batch_size': 32, 'hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0035550811620824437, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:19:36.251+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:19:36,250] Trial 39 finished with value: 0.09116475470364094 and parameters: {'batch_size': 48, 'hidden_size': 160, 'num_layers': 2, 'dropout_rate': 0.4, 'learning_rate': 0.006121546035520065, 'model_type': 'lstm'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:19:48.723+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:19:48,723] Trial 40 finished with value: 0.018786006281152366 and parameters: {'batch_size': 16, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.003982131699137868, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:20:07.323+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:20:07,323] Trial 41 finished with value: 0.01678659892641008 and parameters: {'batch_size': 16, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0024352285905312053, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:20:19.703+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:20:19,703] Trial 42 finished with value: 0.01793972202576697 and parameters: {'batch_size': 16, 'hidden_size': 160, 'num_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 0.0029874480285164108, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:20:26.725+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:20:26,724] Trial 43 finished with value: 0.03972419947385788 and parameters: {'batch_size': 32, 'hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.4, 'learning_rate': 0.0022230092611172565, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:20:45.713+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:20:45,713] Trial 44 finished with value: 0.015010720631107689 and parameters: {'batch_size': 16, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.004862431701707794, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:20:48.078+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:20:48,078] Trial 45 finished with value: 0.06831549480557442 and parameters: {'batch_size': 32, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.005427582867900218, 'model_type': 'lstm_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:21:03.779+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:21:03,779] Trial 46 finished with value: 0.049930029455572365 and parameters: {'batch_size': 16, 'hidden_size': 160, 'num_layers': 2, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.00960649664241447, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:21:08.415+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:21:08,415] Trial 47 finished with value: 0.044998543336987495 and parameters: {'batch_size': 96, 'hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.4, 'learning_rate': 0.003639480115113134, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:21:20.703+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:21:20,703] Trial 48 finished with value: 0.029040765715762973 and parameters: {'batch_size': 48, 'hidden_size': 160, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0052962600420641895, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:21:37.211+0000] {subprocess.py:106} INFO - [I 2025-04-14 08:21:37,211] Trial 49 finished with value: 0.03851506362358729 and parameters: {'batch_size': 64, 'hidden_size': 192, 'num_layers': 1, 'dropout_rate': 0.4, 'learning_rate': 0.0013470978272141665, 'model_type': 'lstm_cross_attention'}. Best is trial 37 with value: 0.014010190684348344.
[2025-04-14T08:21:37.215+0000] {subprocess.py:106} INFO - Using device: cpu
[2025-04-14T08:21:37.216+0000] {subprocess.py:106} INFO - --- Loading Scaled Data from /opt/***/data/features/split_scaled_data.npz ---
[2025-04-14T08:21:37.217+0000] {subprocess.py:106} INFO - --- Finished Loading Scaled Data ---
[2025-04-14T08:21:37.218+0000] {subprocess.py:106} INFO - --- Loading Scalers from /opt/***/data/processed/scalers.pkl ---
[2025-04-14T08:21:37.218+0000] {subprocess.py:106} INFO - --- Finished Loading Scalers ---
[2025-04-14T08:21:37.219+0000] {subprocess.py:106} INFO - --- Starting Optuna Optimization (50 trials) ---
[2025-04-14T08:21:37.219+0000] {subprocess.py:106} INFO - Early stopping at epoch 14
[2025-04-14T08:21:37.220+0000] {subprocess.py:106} INFO - Early stopping at epoch 7
[2025-04-14T08:21:37.220+0000] {subprocess.py:106} INFO - Early stopping at epoch 7
[2025-04-14T08:21:37.220+0000] {subprocess.py:106} INFO - Early stopping at epoch 16
[2025-04-14T08:21:37.221+0000] {subprocess.py:106} INFO - Early stopping at epoch 18
[2025-04-14T08:21:37.222+0000] {subprocess.py:106} INFO - Early stopping at epoch 18
[2025-04-14T08:21:37.222+0000] {subprocess.py:106} INFO - Early stopping at epoch 9
[2025-04-14T08:21:37.223+0000] {subprocess.py:106} INFO - Early stopping at epoch 9
[2025-04-14T08:21:37.223+0000] {subprocess.py:106} INFO - Early stopping at epoch 12
[2025-04-14T08:21:37.224+0000] {subprocess.py:106} INFO - Early stopping at epoch 15
[2025-04-14T08:21:37.225+0000] {subprocess.py:106} INFO - Early stopping at epoch 19
[2025-04-14T08:21:37.225+0000] {subprocess.py:106} INFO - Early stopping at epoch 13
[2025-04-14T08:21:37.226+0000] {subprocess.py:106} INFO - Early stopping at epoch 10
[2025-04-14T08:21:37.226+0000] {subprocess.py:106} INFO - Early stopping at epoch 13
[2025-04-14T08:21:37.227+0000] {subprocess.py:106} INFO - Early stopping at epoch 13
[2025-04-14T08:21:37.227+0000] {subprocess.py:106} INFO - Early stopping at epoch 13
[2025-04-14T08:21:37.228+0000] {subprocess.py:106} INFO - Early stopping at epoch 11
[2025-04-14T08:21:37.228+0000] {subprocess.py:106} INFO - Early stopping at epoch 5
[2025-04-14T08:21:37.229+0000] {subprocess.py:106} INFO - Early stopping at epoch 8
[2025-04-14T08:21:37.229+0000] {subprocess.py:106} INFO - Early stopping at epoch 15
[2025-04-14T08:21:37.229+0000] {subprocess.py:106} INFO - Early stopping at epoch 17
[2025-04-14T08:21:37.230+0000] {subprocess.py:106} INFO - Early stopping at epoch 8
[2025-04-14T08:21:37.230+0000] {subprocess.py:106} INFO - Early stopping at epoch 8
[2025-04-14T08:21:37.231+0000] {subprocess.py:106} INFO - Early stopping at epoch 13
[2025-04-14T08:21:37.231+0000] {subprocess.py:106} INFO - Early stopping at epoch 14
[2025-04-14T08:21:37.231+0000] {subprocess.py:106} INFO - Early stopping at epoch 14
[2025-04-14T08:21:37.232+0000] {subprocess.py:106} INFO - Early stopping at epoch 7
[2025-04-14T08:21:37.232+0000] {subprocess.py:106} INFO - Early stopping at epoch 17
[2025-04-14T08:21:37.233+0000] {subprocess.py:106} INFO - Early stopping at epoch 11
[2025-04-14T08:21:37.233+0000] {subprocess.py:106} INFO - Early stopping at epoch 17
[2025-04-14T08:21:37.234+0000] {subprocess.py:106} INFO - Early stopping at epoch 14
[2025-04-14T08:21:37.234+0000] {subprocess.py:106} INFO - Early stopping at epoch 14
[2025-04-14T08:21:37.235+0000] {subprocess.py:106} INFO - Early stopping at epoch 16
[2025-04-14T08:21:37.235+0000] {subprocess.py:106} INFO - Early stopping at epoch 11
[2025-04-14T08:21:37.235+0000] {subprocess.py:106} INFO - Early stopping at epoch 14
[2025-04-14T08:21:37.236+0000] {subprocess.py:106} INFO - Early stopping at epoch 12
[2025-04-14T08:21:37.236+0000] {subprocess.py:106} INFO - Early stopping at epoch 9
[2025-04-14T08:21:37.237+0000] {subprocess.py:106} INFO - Early stopping at epoch 16
[2025-04-14T08:21:37.237+0000] {subprocess.py:106} INFO - Early stopping at epoch 7
[2025-04-14T08:21:37.238+0000] {subprocess.py:106} INFO - Early stopping at epoch 7
[2025-04-14T08:21:37.238+0000] {subprocess.py:106} INFO - Early stopping at epoch 11
[2025-04-14T08:21:37.239+0000] {subprocess.py:106} INFO - Early stopping at epoch 16
[2025-04-14T08:21:37.239+0000] {subprocess.py:106} INFO - --- Finished Optuna Optimization ---
[2025-04-14T08:21:37.240+0000] {subprocess.py:106} INFO - Best trial value (loss): 0.014010190684348344
[2025-04-14T08:21:37.240+0000] {subprocess.py:106} INFO - Best parameters: {'batch_size': 16, 'hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0034994428915323724, 'model_type': 'lstm_cross_attention'}
[2025-04-14T08:21:37.241+0000] {subprocess.py:106} INFO - --- Saving Best Parameters to /opt/***/config/best_params.json ---
[2025-04-14T08:21:37.241+0000] {subprocess.py:106} INFO - --- Finished Saving Best Parameters ---
[2025-04-14T08:21:38.591+0000] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-14T08:21:38.618+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-14T08:21:38.619+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=lstm_stock_prediction_refactored, task_id=optimize_hyperparams, run_id=scheduled__2025-04-07T08:00:00+00:00, execution_date=20250407T080000, start_date=20250414T080005, end_date=20250414T082138
[2025-04-14T08:21:38.681+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-14T08:21:38.703+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-14T08:21:38.706+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
