**Comprehensive Flow of the Final Airflow DAGs**

**I. Overall General Flow & Interaction**

1.  **Daily Cycle (`daily_stock_operations_prod` DAG):**
    *   Runs automatically on a schedule (e.g., weekdays after market close).
    *   Fetches the latest raw stock data.
    *   Identifies the current "Production" model from MLflow.
    *   Prepares the necessary input sequence tailored for that specific production model (using its associated scalers and feature definitions).
    *   Generates predictions for the next trading day.
    *   Saves these predictions for the API/dashboard and logs them to the database.
    *   Evaluates the accuracy of predictions made for a *previous* day (e.g., yesterday) against the actual market outcome.
    *   Based on performance thresholds, decides whether the model is performing adequately.
2.  **Retraining Trigger:**
    *   If the daily monitoring task finds that the production model's performance has dropped below acceptable levels, it triggers the `stock_model_retraining_prod` DAG.
    *   If performance is acceptable, the daily DAG finishes.
3.  **Retraining Cycle (`stock_model_retraining_prod` DAG):**
    *   Runs only when triggered.
    *   Takes *all* available, up-to-date raw data and processes it into a *new, versioned dataset* (identified by a new `dataset_run_id`).
    *   Optimizes hyperparameters for this new dataset version.
    *   Trains a new "candidate" model using this versioned data and optimized parameters.
    *   Logs the candidate model and its training details (including the `dataset_run_id` it used) to MLflow and registers it.
    *   Compares the performance of this new candidate model against the current Production model (ideally on the same test set derived from the new data).
    *   If the candidate is superior, it promotes the candidate model to the "Production" stage in the MLflow Model Registry.

---

**II. Detailed Flow: `daily_stock_operations_prod` DAG**

*   **DAG ID (Example):** `daily_stock_operations_prod`
*   **Schedule (Example):** `0 1 * * 1-5` (1 AM UTC Weekdays)
*   **Purpose:** Daily data ingestion, prediction, monitoring, and triggering retraining.

| Task ID (`task_id`)                          | Operator Type     | Script Executed (Path from PROJECT_ROOT)      | Inputs                                                                                                                                  | Key Outputs & Side Effects                                                                                                                                                                                                                            | Config Used (`params.yaml`)                                                                                                |
| :------------------------------------------- | :---------------- | :-------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- |
| `initialize_database_daily_check`          | `PythonOperator`  | `src.utils.db_utils.setup_database` (callable)  | `CONFIG_PATH` (for DB config)                                                                                                             | Ensures PostgreSQL tables (`raw_stock_data`, `model_performance_log`, `latest_predictions`, etc.) exist.                                                                                                                                                    | `database`                                                                                                                   |
| `fetch_incremental_raw_data_daily`         | `BashOperator`    | `src/data/make_dataset.py`                    | `--config CONFIG_PATH`, `--mode incremental_fetch`                                                                                        | Fetches new data since last DB entry from Yahoo Finance. Updates/inserts rows into `raw_stock_data` table.                                                                                                                                                | `database`, `data_loading`                                                                                                   |
| `get_production_model_info_daily`          | `PythonOperator`  | `callable_get_production_model_info_for_daily`  | `CONFIG_PATH` (for MLflow config). Queries MLflow Model Registry.                                                                         | Pushes to XComs: `production_model_uri` (e.g., "models:/ModelName/Production" or specific version), `production_model_training_dataset_run_id` (e.g., "20231101_100000").                                                                                    | `mlflow` (tracking_uri, experiment_name/registered_model_name)                                                               |
| `prepare_daily_prediction_input`           | `BashOperator`    | `src/features/prepare_prediction_input.py`    | `--config CONFIG_PATH`, `--production_model_training_run_id` (from XCom `get...info`), `--output_dir <temp_path>` (e.g., `/tmp/...`). Reads `scalers` and `processed_feature_data` tables (using dataset_run_id). Reads `raw_stock_data` table. | Creates `.npy` file in `--output_dir` containing the scaled input sequence `(1, seq, stocks, feats)`. Prints `OUTPUT_PATH:<filepath>` to stdout. Pushes stdout string to XCom `return_value`.                                                         | `database`, `feature_engineering` (sequence_length).                                                                     |
| `make_daily_prediction`                      | `BashOperator`    | `src/models/predict_model.py`                 | `--config CONFIG_PATH`, `--input_sequence_path` (parsed from XCom `prepare...input`), `--production_model_uri` (from XCom `get...info`). Reads `.npy` file. Loads model from MLflow. Reads `scalers` table (using model's dataset_run_id). | Makes prediction. Saves prediction to `latest_predictions` table (value + model's MLflow run ID). Creates/updates `latest_predictions.json` & `historical/{date}.json` files in `predictions_dir`.                                                  | `database`, `mlflow` (tracking_uri), `output_paths` (predictions_dir).                                                         |
| `monitor_model_performance_task`           | `BashOperator`    | `src/models/monitor_performance.py`           | `--config CONFIG_PATH`. Reads historical prediction JSON (or DB `latest_predictions`). Reads `raw_stock_data`.                               | Calculates metrics for `prediction_date_to_evaluate`. Saves metrics to `model_performance_log` table (linked to model's MLflow run ID). Prints `NEXT_TASK_ID:<task_id_string>` to stdout. Pushes stdout string to XCom `return_value`.              | `database`, `data_loading` (tickers), `monitoring` (thresholds, lag_days), `output_paths` (predictions_dir), `airflow_dags` (task IDs). |
| `branch_on_monitoring_decision`            | `BranchPythonOp`  | `callable_branch_on_monitoring_result`        | Pulls XCom `return_value` from `monitor_model_performance_task`.                                                                        | Returns the target Task ID string (`trigger_retraining_task_id` or `no_retraining_task_id`) based on monitoring output.                                                                                                                            | `airflow_dags` (task IDs for branching).                                                                                   |
| `trigger_retraining_pipeline_task` (Task ID from `params.yaml`) | `TriggerDagRunOp` | N/A                                           | `trigger_dag_id` (retraining DAG ID from `params.yaml`).                                                                     | Initiates a run of the `stock_model_retraining_prod` DAG.                                                                                                                                                                                               | `airflow_dags` (retraining_pipeline_dag_id).                                                                               |
| `no_retraining_needed_task` (Task ID from `params.yaml`)       | `DummyOperator`   | N/A                                           | N/A                                                                                                                       | Represents the end of the workflow when retraining is not needed.                                                                                                                                                                                          | N/A                                                                                                                        |

---

**III. Detailed Flow: `stock_model_retraining_prod` DAG**

*   **DAG ID (Example):** `stock_model_retraining_prod`
*   **Schedule:** `None` (Triggered)
*   **Purpose:** Retrain the model using all available data, evaluate, and promote if better.

| Task ID (`task_id`)                     | Operator Type     | Script Executed (Path from PROJECT_ROOT)                      | Inputs                                                                                              | Key Outputs & Side Effects                                                                                                                                                                                                           | Config Used (`params.yaml`)                                                                                                                 |
| :-------------------------------------- | :---------------- | :------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------ |
| `initialize_database_for_retraining`    | `PythonOperator`  | `src.utils.db_utils.setup_database` (callable)                | `CONFIG_PATH` (for DB config)                                                                         | Ensures PostgreSQL tables exist.                                                                                                                                                                                                           | `database`                                                                                                                    |
| `process_all_data_for_retraining`     | `PythonOperator`  | `src.data.make_dataset.py` (`callable...`, mode=`full_process`) | `--config CONFIG_PATH`, `--mode full_process`. Reads `raw_stock_data` table.                         | Updates `raw_stock_data`. Creates new row in `processed_feature_data` table with **new** `dataset_run_id`. Pushes `new_dataset_run_id` to XComs (key=`new_dataset_run_id`).                                                            | `database`, `data_loading`, `feature_engineering`.                                                                                            |
| `build_features_for_retraining`       | `BashOperator`    | `src/features/build_features.py`                              | `--config CONFIG_PATH`, `--run_id` (pulled `new_dataset_run_id` from XCom). Reads `processed_feature_data` (using run_id). | Creates rows in `scaled_feature_sets` table and `scalers` table, linked to the `new_dataset_run_id`.                                                                                                                               | `database`, `feature_engineering`.                                                                                              |
| `optimize_hyperparams_for_retraining` | `BashOperator`    | `src/models/optimize_hyperparams.py`                          | `--config CONFIG_PATH`, `--run_id` (pulled `new_dataset_run_id` from XCom). Reads `scaled_feature_sets` and `scalers` (using run_id). | Creates row in `optimization_results` table, linked to the `new_dataset_run_id`. (Optionally updates `best_params.json` file).                                                                                                      | `database`, `optimization`, `output_paths` (optional).                                                                          |
| `train_candidate_model_task`          | `PythonOperator`  | `src.models.train_model.py` (`callable...`)                   | `--config CONFIG_PATH`, `--run_id` (pulled `new_dataset_run_id` from XCom). Reads `scaled_feature_sets`, `scalers`, `optimization_results` (using run_id). | Trains model. Logs params (incl. `new_dataset_run_id`), metrics, model artifact to **new MLflow Run**. Registers model in MLflow Registry (initial stage). Pushes **candidate model's MLflow Run ID** and the `new_dataset_run_id` to XComs. | `database`, `training`, `mlflow`, `output_paths` (plots).                                                                       |
| `evaluate_and_promote_candidate_branch` | `BranchPythonOp`  | `callable_evaluate_and_promote_candidate`                     | Pulls `candidate_model_mlflow_run_id` & `candidate_training_dataset_run_id` from XComs. `CONFIG_PATH`. Queries MLflow for candidate metrics & production model info. (May read test data from `scaled_feature_sets` for comparison). | Compares models. If candidate is better, transitions candidate version to "Production" stage in MLflow Registry (archives old). Returns Task ID string (`promotion_complete_task` or `do_not_promote_candidate_task`).           | `mlflow`, `model_promotion` (metrics, comparison logic), `database`.                                                                |
| `promotion_complete_task` (Example ID)  | `DummyOperator`   | N/A                                                           | N/A                                                                                                   | Represents successful promotion branch. MLflow Model Registry was updated by the previous task.                                                                                                                                    | N/A                                                                                                                             |
| `do_not_promote_candidate_task` (Example ID) | `DummyOperator`   | N/A                                                           | N/A                                                                                                   | Represents branch where candidate was not promoted.                                                                                                                                                                                | N/A                                                                                                                             |
