data_loading:
  tickers: ['AAPL', 'MA', 'CSCO', 'MSFT', 'AMZN', 'GOOG', 'IBM']
  period: "1y"
  interval: "1d"
  fetch_delay: 10

feature_engineering:
  correlation_threshold: 0.9
  sequence_length: 30
  prediction_length: 1 # Currently only supporting 1-day ahead

optimization:
  n_trials: 1
  epochs: 5 
  patience: 5

training:
  epochs: 5

database:
  dbname: 'airflow'
  user: 'airflow'
  password: 'airflow'
  host: 'postgres'
  port: '5432'

monitoring:
  performance_thresholds:
    mape_max: 0.10        # Threshold: Max 10% MAPE
    direction_accuracy_min: 0.55 # Threshold: Min 55% directional accuracy
  evaluation_lag_days: 1 # How many days to wait for actuals (e.g., T+1 for stock prices)

airflow_dags:
  daily_operations_dag_id: "daily_stock_operations"
  retraining_pipeline_dag_id: "stock_model_retraining_pipeline"

output_paths:
  raw_data_template: "/opt/airflow/data/raw/{ticker}_raw.pkl"
  # processed_data_path: "/opt/airflow/data/processed/all_processed_data.npz" # Saving as numpy archive
  # scalers_path: "/opt/airflow/data/processed/scalers.pkl"
  # split_data_path: "/opt/airflow/data/features/split_scaled_data.npz"
  # best_params_path: "/opt/airflow/config/best_params.json" # Config might also need absolute if written by a task
  # Note: We are mounting ./config to /opt/airflow/config, so this path for best_params is correct

mlflow:
  experiment_name: "Stock_Price_Prediction_LSTM_Refactored"
  final_run_name: "final_model_training"
  optuna_run_prefix: "optuna_trial_" # Prefix for Optuna runs
  mlflow_uri: "http://mlflow-server:5000" # MLflow server URI (internal to Docker network)
  tracking_uri: "http://mlflow-server:5000" # MLflow tracking URI (internal to Docker network)